# -*- coding: utf-8 -*-
"""
ğŸ¨ é…’åº—è¿è¥ä¸€ä½“åŒ–ç³»ç»Ÿ
åŠŸèƒ½ï¼šæºç¨‹/ç¾å›¢è¯„åˆ†è®¡ç®— + è¯„è®ºç»´åº¦åˆ†æï¼ˆæ–‡æœ¬æŒ–æ˜ï¼‰+ æ™ºèƒ½è¯„è®ºå›å¤
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from io import BytesIO
import base64
import requests
import time
import re
import os
from datetime import datetime
import jieba
from collections import defaultdict
import squarify
import matplotlib

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
matplotlib.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans', 'Microsoft YaHei']
matplotlib.rcParams['axes.unicode_minus'] = False

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(page_title="Hotel OTA", layout="centered")

# ==================== åˆå§‹åŒ– session_state ====================
if 'history' not in st.session_state:
    st.session_state.history = []

if 'hotel_name' not in st.session_state:
    st.session_state.hotel_name = "æ˜Ÿè¾°èŠ±å›­é…’åº—"
if 'hotel_nickname' not in st.session_state:
    st.session_state.hotel_nickname = "å°æ²¹"

# ==================== å·¥å…·å‡½æ•°ï¼šExcel å¯¼å‡º ====================
def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='åŸå§‹æ•°æ®')
    return output.getvalue()

# ==================== å·¥å…·å‡½æ•°ï¼šåŠ æƒè¯„åˆ†è®¡ç®— ====================
def calculate_time_and_rank_weighted_score(df, score_col, date_col="å…¥ä½æ—¶é—´"):
    df = df.copy()
    df[score_col] = pd.to_numeric(df[score_col], errors='coerce')
    df = df.dropna(subset=[score_col, date_col])
    df = df[(df[score_col] >= 1) & (df[score_col] <= 5)]

    if len(df) == 0:
        return 0.0

    try:
        df[date_col] = pd.to_datetime(df[date_col])
    except Exception as e:
        st.error(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼š{e}")
        return 0.0

    lambda_decay = 0.05
    latest_date = df[date_col].max()
    df['å¤©æ•°å·®'] = (latest_date - df[date_col]).dt.days
    df['æ—¶é—´æƒé‡'] = np.exp(-lambda_decay * df['å¤©æ•°å·®'])

    weight_map = {5: 1, 4: 2, 3: 3, 2: 4, 1: 5}
    df['è¯„åˆ†æƒé‡'] = df[score_col].map(weight_map)
    df['æ€»æƒé‡'] = df['æ—¶é—´æƒé‡'] * df['è¯„åˆ†æƒé‡']
    df['åŠ æƒåˆ†æ•°'] = df[score_col] * df['æ€»æƒé‡']

    total_weighted_score = df['åŠ æƒåˆ†æ•°'].sum()
    total_weight = df['æ€»æƒé‡'].sum()

    if total_weight == 0:
        return 0.0

    weighted_avg = total_weighted_score / total_weight
    final_score = max(weighted_avg - 0.20, 1.0)
    return round(final_score, 2)

# ==================== å·¥å…·å‡½æ•°ï¼šæƒ…æ„Ÿåˆ†æä¸æ ‡ç­¾æå– ====================
TAG_KEYWORDS = {
    'ä½ç½®': ['ä½ç½®', 'åœ°æ®µ', 'å‘¨è¾¹', 'é™„è¿‘', 'ç¦»', 'é è¿‘', 'å¸‚ä¸­å¿ƒ', 'åœ°é“', 'å…¬äº¤'],
    'äº¤é€š': ['äº¤é€š', 'æ‰“è½¦', 'åœè½¦', 'é©¾è½¦', 'æœºåœº', 'è½¦ç«™', 'æ¥é©³'],
    'æ—©é¤': ['æ—©é¤', 'æ—©é¥­', 'é¤é¥®', 'buffet', 'é¤é£Ÿ', 'è‡ªåŠ©é¤'],
    'å®‰é™': ['å®‰é™', 'å™ªéŸ³', 'åµ', 'åµé—¹', 'éš”éŸ³', 'æ¸…é™', 'å®‰é™æˆ¿'],
    'åºŠèˆ’é€‚': ['åºŠ', 'åºŠå«', 'ç¡æ„Ÿ', 'èˆ’æœ', 'èˆ’ä¸èˆ’æœ', 'è½¯ç¡¬', 'æ•å¤´'],
    'æˆ¿é—´å¤§å°': ['æˆ¿é—´å°', 'æˆ¿é—´å¤§', 'ç©ºé—´', 'æ‹¥æŒ¤', 'å®½æ•', 'é¢ç§¯', 'å±€ä¿ƒ'],
    'è§†é‡': ['è§†é‡', 'æ™¯è§‚', 'æ±Ÿæ™¯', 'æµ·æ™¯', 'çª—æ™¯', 'æœå‘', 'å¤œæ™¯', 'view'],
    'æ€§ä»·æ¯”': ['æ€§ä»·æ¯”', 'ä»·æ ¼', 'åˆ’ç®—', 'è´µ', 'ä¾¿å®œ', 'å€¼', 'ç‰©è¶…æ‰€å€¼'],
    'å‰å°': ['å‰å°', 'æ¥å¾…', 'check in', 'å…¥ä½åŠç†', 'é€€æˆ¿', 'æ¥å¾…å‘˜'],
    'ç½‘ç»œ': ['Wi-Fi', 'ç½‘ç»œ', 'ä¿¡å·', 'ä¸Šç½‘', 'ç½‘é€Ÿ', 'wifi', 'æ— çº¿']
}

POSITIVE_WORDS = {'å¥½', 'æ£’', 'èµ', 'æ»¡æ„', 'ä¸é”™', 'æ¨è', 'æƒŠå–œ', 'èˆ’æœ', 'å®Œç¾', 'è´´å¿ƒ',
                  'å¹²å‡€', 'æ–¹ä¾¿', 'å¿«æ·', 'æ¸©é¦¨', 'æŸ”è½¯', 'ä¸°å¯Œ', 'é½å…¨', 'ä¼˜è´¨', 'çƒ­æƒ…'}
NEGATIVE_WORDS = {'å·®', 'ç³Ÿ', 'çƒ‚', 'å‘', 'å·®åŠ²', 'å¤±æœ›', 'ç³Ÿç³•', 'éš¾ç”¨', 'åµ', 'è„',
                  'è´µ', 'å', 'æ…¢', 'ä¸å€¼', 'é—®é¢˜', 'æ•·è¡', 'æ‹–å»¶', 'æ¶åŠ£'}

def preprocess(text):
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z]', '', str(text).lower())
    words = jieba.lcut(text)
    return [w for w in words if len(w) >= 2]

def get_sentiment_score(text):
    words = preprocess(text)
    pos_count = sum(1 for w in words if w in POSITIVE_WORDS)
    neg_count = sum(1 for w in words if w in NEGATIVE_WORDS)
    total = pos_count + neg_count
    if total == 0:
        return 3.8
    if pos_count > neg_count:
        return min(5.0, 4.5 + 0.5 * (pos_count / total))
    elif neg_count > pos_count:
        return max(1.0, 2.5 - 0.5 * (neg_count / total))
    else:
        return 3.8

def extract_tags_with_scores(comments):
    tag_scores = defaultdict(list)
    for comment in comments.dropna():
        for tag, keywords in TAG_KEYWORDS.items():
            if any(kw in str(comment) for kw in keywords):
                score = get_sentiment_score(str(comment))
                tag_scores[tag].append(score)
    final_scores = {
        tag: round(sum(scores) / len(scores), 2)
        for tag, scores in tag_scores.items()
        if len(scores) > 0
    }
    return final_scores

# ==================== å·¥å…·å‡½æ•°ï¼šæ™ºèƒ½è¯„è®ºå›å¤ ====================
def extract_aspects_and_sentiment(review: str) -> dict:
    aspects = {
        'äº¤é€š': ['åœ°é“', 'äº¤é€š', 'åœè½¦', 'ä½ç½®', 'æ–¹ä¾¿', 'ç›´è¾¾', 'é«˜é“', 'ç«è½¦ç«™'],
        'æœåŠ¡': ['æœåŠ¡', 'å‰å°', 'çƒ­æƒ…', 'å‘¨åˆ°', 'ä¸“ä¸š', 'å“åº”', 'å¤„ç†'],
        'å«ç”Ÿ': ['å¹²å‡€', 'å«ç”Ÿ', 'æ•´æ´', 'æ— å¼‚å‘³', 'ä¸€å°˜ä¸æŸ“', 'è„', 'ç°å°˜'],
        'æ—©é¤': ['æ—©é¤', 'å¯å£', 'ä¸°å¯Œ', 'ç¾å‘³', 'ç§ç±»', 'å¥¶é…¥åŒ…', 'ç°çƒ¤'],
        'æ€§ä»·æ¯”': ['æ€§ä»·æ¯”', 'åˆ’ç®—', 'ä¾¿å®œ', 'ç‰©è¶…æ‰€å€¼', 'è´µ'],
        'ç¯å¢ƒ': ['ç¯å¢ƒ', 'å®‰é™', 'èˆ’é€‚', 'ä¼˜ç¾', 'é£æ™¯', 'éš”éŸ³', 'åµ', 'å™ªéŸ³'],
        'è®¾æ–½': ['è®¾æ–½', 'é™ˆæ—§', 'è€åŒ–', 'æ™ºèƒ½', 'ç©ºè°ƒ', 'ç”µè§†', 'åºŠå“', 'åœ°æ¯¯', 'å£çº¸']
    }
    found = []
    for k, keywords in aspects.items():
        if any(w in review.lower() for w in [w.lower() for w in keywords]):
            found.append(k)

    pos_words = ['å¥½', 'æ£’', 'æ»¡æ„', 'å–œæ¬¢', 'æ¨è', 'èˆ’æœ', 'ä¸“ä¸š', 'å‘¨åˆ°', 'å¯å£', 'æ–¹ä¾¿', 'å®‰é™', 'æ•´æ´']
    neg_words = ['å·®', 'ç³Ÿ', 'å¤±æœ›', 'è„', 'æ…¢', 'è´µ', 'é—®é¢˜', 'åµ', 'æŸå', 'é—æ†¾', 'é™ˆæ—§', 'å™ªéŸ³', 'ä¸éš”éŸ³']

    pos_score = sum(review.lower().count(w) for w in [w.lower() for w in pos_words])
    neg_score = sum(review.lower().count(w) for w in [w.lower() for w in neg_words])

    sentiment = "æ­£é¢" if pos_score > neg_score else "è´Ÿé¢" if neg_score > pos_score else "ä¸­æ€§"

    return {
        "aspects": list(set(found)),
        "sentiment": sentiment,
        "has_complaint": neg_score > 0,
        "has_praise": pos_score > 0,
        "has_facility_issue": any(w in review for w in ['é™ˆæ—§', 'è€åŒ–', 'æŸå', 'æ•…éšœ', 'æ—§']),
        "has_noise": any(w in review for w in ['åµ', 'å™ªéŸ³', 'ä¸éš”éŸ³', 'å®‰é™']),
        "has_service_staff": bool(re.search(r'[a-zA-Z\u4e00-\u9fff]{2,4}', review))
    }

def generate_prompt(review: str, guest_name: str, hotel_name, hotel_nickname, review_source):
    info = extract_aspects_and_sentiment(review)

    tag_map = {
        'äº¤é€š': 'ã€â¤ï¸äº¤é€šä¾¿åˆ©â¤ï¸ã€‘',
        'æœåŠ¡': 'ã€â¤ï¸æœåŠ¡å‘¨åˆ°â¤ï¸ã€‘',
        'å«ç”Ÿ': 'ã€âœ…å¹²å‡€æ•´æ´âœ…ã€‘',
        'æ—©é¤': 'ã€ğŸ³æ—©é¤å¯å£ğŸ³ã€‘',
        'æ€§ä»·æ¯”': 'ã€ğŸ’°æ€§ä»·æ¯”é«˜ğŸ’°ã€‘',
        'ç¯å¢ƒ': 'ã€ğŸŒ¿å®‰é™èˆ’é€‚ğŸŒ¿ã€‘',
        'è®¾æ–½': 'ã€ğŸ”§è®¾æ–½å®Œå–„ğŸ”§ã€‘'
    }
    tags = "".join(tag_map[aspect] for aspect in info['aspects'] if aspect in tag_map and info['sentiment'] != "è´Ÿé¢")
    if not tags:
        tags = "ã€ğŸ¨èˆ’é€‚å…¥ä½ğŸ¨ã€‘"

    prompt = f"""
    ä½ æ˜¯ {hotel_name} çš„å®¢æœåŠ©æ‰‹â€œ{hotel_nickname}â€ï¼Œæ­£åœ¨å›å¤å®¢äººåœ¨ {review_source} ä¸Šçš„è¯„è®ºã€‚
    è¯·ç”¨è§„èŒƒã€ä¸“ä¸šã€çœŸè¯šçš„è¯­æ°”æ’°å†™å›å¤ã€‚

    è¦æ±‚ï¼š
    1. å¼€å¤´ä½¿ç”¨æ ‡ç­¾ï¼š{tags}
    2. ç§°å‘¼ï¼šâ€œå°Šæ•¬çš„å®¾å®¢â€æˆ–â€œäº²çˆ±çš„{guest_name}â€
    3. å¥½è¯„ï¼šæ„Ÿè°¢ + è®¤å¯
    4. å·®è¯„ï¼šè‡´æ­‰ + æ•´æ”¹æªæ–½
    5. ä¸¥æ ¼æ§åˆ¶åœ¨100-200ä¸ªæ±‰å­—ä¹‹é—´
    6. ä¸ä½¿ç”¨è¯—å¥ã€å“²ç†ã€ç½‘ç»œç”¨è¯­
    7. ç»“å°¾è¡¨è¾¾æœŸå¾…å†æ¬¡å…‰ä¸´

    ã€å®¢äººè¯„è®ºã€‘ï¼š
    {review}
    """
    return prompt

def call_qwen_api(prompt: str) -> str:
    api_key = os.getenv("QWEN_API_KEY")
    if not api_key:
        return "âŒ æœªè®¾ç½® QWEN_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­é…ç½®ã€‚"

    headers = {
        'Authorization': f'Bearer {api_key}',
        'Content-Type': 'application/json'
    }
    payload = {
        "model": "qwen-max",
        "input": {
            "messages": [{"role": "user", "content": prompt}]
        },
        "parameters": {
            "result_format": "text",
            "max_tokens": 200,
            "temperature": 0.6,
            "top_p": 0.85
        }
    }
    try:
        response = requests.post("https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
                                 headers=headers, json=payload, timeout=30)
        if response.status_code == 200:
            result = response.json()
            return result['output']['text'].strip()
        else:
            return f"âŒ API é”™è¯¯ [{response.status_code}]ï¼š{response.text}"
    except Exception as e:
        return f"ğŸš¨ è¯·æ±‚å¤±è´¥ï¼š{str(e)}"

def truncate_to_word_count(text: str, min_words=100, max_words=200) -> str:
    words = [c for c in text if c.isalnum() or c in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€']
    content = ''.join(words)
    if len(content) <= max_words:
        return content
    else:
        truncated = content[:max_words]
        for punct in ['ã€‚', 'ï¼', 'ï¼Ÿ']:
            if punct in truncated:
                truncated = truncated[:truncated.rfind(punct) + 1]
                break
        if len(truncated) < min_words:
            truncated = content[:max_words]
        return truncated[:max_words]

# ==================== ä¼˜åŒ–å»ºè®®åº“ ====================
SUGGESTIONS = {
    'æ€»è¯„åˆ†': 'æ•´ä½“ä½“éªŒéœ€æå‡ï¼Œå»ºè®®ä»æœåŠ¡å’Œè®¾æ–½å…¥æ‰‹ï¼ŒåŠ å¼ºå®¢æˆ·åé¦ˆé—­ç¯ç®¡ç†ã€‚',
    'è®¾æ–½è¯„åˆ†': 'æ£€æŸ¥è€æ—§è®¾å¤‡ï¼Œåˆ¶å®šæ›´æ–°è®¡åˆ’ï¼Œå¢åŠ æ™ºèƒ½åŒ–è®¾æ–½å¦‚æ™ºèƒ½é—¨é”ã€è¯­éŸ³åŠ©æ‰‹ã€‚',
    'æœåŠ¡è¯„åˆ†': 'åŠ å¼ºå‘˜å·¥æœåŠ¡æ„è¯†åŸ¹è®­ï¼Œå»ºç«‹å¿«é€Ÿå“åº”æœºåˆ¶å¤„ç†å·®è¯„ã€‚',
    'å«ç”Ÿè¯„åˆ†': 'åŠ å¼ºæ¸…æ´æµç¨‹ç›‘ç£ï¼Œå¼•å…¥ç¬¬ä¸‰æ–¹è´¨æ£€æˆ–å…¬ç¤ºæ¶ˆæ¯’è®°å½•å¢å¼ºä¿¡ä»»ã€‚',
    'ä½ç½®': 'ä¼˜åŒ–å¯¼èˆªä¿¡æ¯ï¼Œä¸å‘¨è¾¹å•†åœˆåˆä½œæä¾›æŠ˜æ‰£å¼¥è¡¥ä½ç½®çŸ­æ¿ã€‚',
    'äº¤é€š': 'æä¾›å…è´¹æ¥é©³è½¦æˆ–ä¸æ‰“è½¦å¹³å°åˆä½œï¼Œæå‡å®¢äººä¾¿åˆ©æ€§ã€‚',
    'æ—©é¤': 'ä¸°å¯Œæ—©é¤å“ç±»ï¼Œå¢åŠ æœ¬åœ°ç‰¹è‰²å’Œå¥åº·é€‰é¡¹ï¼Œæå‡é¤å“æ¸©åº¦ã€‚',
    'å®‰é™': 'ä¼˜åŒ–éš”éŸ³è®¾è®¡ï¼Œæ›´æ¢å¯†å°æ€§æ›´å¥½çš„é—¨çª—ï¼Œå‡å°‘å™ªéŸ³å¹²æ‰°ã€‚',
    'åºŠèˆ’é€‚': 'å‡çº§åºŠå«ä¸åºŠå“æè´¨ï¼Œæä¾›è½¯ç¡¬ä¸¤ç§æ•å¤´ä¾›å®¢äººé€‰æ‹©ã€‚',
    'æˆ¿é—´å¤§å°': 'ä¼˜åŒ–å°æˆ¿å‹ç©ºé—´å¸ƒå±€ï¼Œæ¨å‡ºâ€œå¤§æˆ¿å‹ä¼˜å…ˆå‡çº§â€ä¼˜æƒ æ´»åŠ¨ã€‚',
    'è§†é‡': 'å®šæœŸæ¸…æ´çª—æˆ·ä¸é˜³å°ï¼Œé¿å…æ™¯è§‚é®æŒ¡ï¼Œæ‹æ‘„é«˜è´¨é‡å®£ä¼ å›¾ã€‚',
    'æ€§ä»·æ¯”': 'è°ƒæ•´ä»·æ ¼ç­–ç•¥ï¼Œæ¨å‡ºä¸åŒæ—¶æ®µä¼˜æƒ å¥—é¤ï¼Œå¢åŠ å¢å€¼æœåŠ¡ã€‚',
    'å‰å°': 'ç¼©çŸ­å…¥ä½/é€€æˆ¿ç­‰å¾…æ—¶é—´ï¼Œæ¨è¡Œè‡ªåŠ©æœºæˆ–ç§»åŠ¨ç«¯åŠç†ã€‚',
    'ç½‘ç»œ': 'å‡çº§Wi-Fiå¸¦å®½ï¼Œç¡®ä¿å…¨åŒºåŸŸç¨³å®šè¦†ç›–ï¼Œè®¾ç½®ä¸€é”®è¿æ¥é¡µé¢ã€‚'
}

# ==================== ä¾§è¾¹æ å¯¼èˆª ====================
st.sidebar.title("ğŸ¨ é…’åº—OTA")
page = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½", [
    "ğŸ“Š æºç¨‹è¯„åˆ†è®¡ç®—å™¨",
    "ğŸ“Š ç¾å›¢è¯„åˆ†è®¡ç®—å™¨",
    "ğŸ“ˆ è¯„è®ºç»´åº¦åˆ†æ",
    "ğŸ’¬ æ™ºèƒ½è¯„è®ºå›å¤"
])

# å…¨å±€é…ç½®
st.sidebar.divider()
st.sidebar.subheader("âš™ï¸ é…’åº—é…ç½®")
hotel_name = st.sidebar.text_input("é…’åº—åç§°", st.session_state.hotel_name)
hotel_nickname = st.sidebar.text_input("åŠ©æ‰‹æ˜µç§°", st.session_state.hotel_nickname)
if st.sidebar.button("ğŸ’¾ ä¿å­˜é…ç½®"):
    st.session_state.hotel_name = hotel_name.strip() or "æœªå‘½åé…’åº—"
    st.session_state.hotel_nickname = hotel_nickname.strip() or "åŠ©æ‰‹"
    st.sidebar.success("âœ… é…ç½®å·²ä¿å­˜")

# ==================== ä¸»é¡µé¢é€»è¾‘ ====================

# ============ 1. æºç¨‹è¯„åˆ†è®¡ç®—å™¨ ============
if page == "ğŸ“Š æºç¨‹è¯„åˆ†è®¡ç®—å™¨":
    st.title("æºç¨‹é…’åº—è¯„åˆ†æå‡è®¡ç®—å™¨")

    col1, col2, col3 = st.columns(3)
    with col1:
        weighted_current_score = st.number_input("å½“å‰åŠ æƒç»¼åˆè¯„åˆ†", 0.0, 5.0, 4.52, 0.01)
        score_3_years_ago = st.number_input("ä¸‰å¹´å‰è¯„åˆ†", 0.0, 5.0, 4.70, 0.01)
    with col2:
        reviews_last_3_years = st.number_input("è¿‘ä¸‰å¹´è¯„ä»·æ•°", 0, 10000, 500, 1)
        reviews_before_3_years = st.number_input("ä¸‰å¹´å‰è¯„ä»·æ•°", 0, 10000, 300, 1)
    with col3:
        target_score = st.number_input("ç›®æ ‡è¯„åˆ†", 0.0, 5.0, 4.80, 0.01)

    def calculate_xiecheng():
        effective_old = reviews_before_3_years / 10.0
        total_weight = reviews_last_3_years + effective_old
        inferred_recent_score = (
            (weighted_current_score * total_weight - score_3_years_ago * effective_old)
            / reviews_last_3_years
        )
        if weighted_current_score >= target_score:
            return 0, inferred_recent_score

        numerator = (target_score * total_weight - score_3_years_ago * effective_old) - inferred_recent_score * reviews_last_3_years
        denominator = 5.0 - target_score
        if denominator <= 0:
            raise ValueError("ç›®æ ‡è¯„åˆ†è¿‡é«˜")
        required = math.ceil(numerator / denominator)
        return max(0, required), inferred_recent_score

    try:
        req, inferred = calculate_xiecheng()
        st.success(f"âœ… åæ¨å‡ºè¿‘ä¸‰å¹´çœŸå®è¯„åˆ†ä¸ºï¼š**{inferred:.3f} åˆ†**")
        if req == 0:
            st.info(f"ğŸ‰ å½“å‰è¯„åˆ†å·²è¾¾åˆ°ç›®æ ‡ **{target_score:.2f}** åˆ†")
        else:
            st.warning(f"ğŸ“ˆ éœ€è¦è‡³å°‘ **{req}** æ¡ 5 æ˜Ÿå¥½è¯„")
    except Exception as e:
        st.error(f"âŒ è®¡ç®—é”™è¯¯ï¼š{str(e)}")

# ============ 2. ç¾å›¢è¯„åˆ†è®¡ç®—å™¨ ============
elif page == "ğŸ“Š ç¾å›¢è¯„åˆ†è®¡ç®—å™¨":
    st.title("ç¾å›¢é…’åº—è¯„åˆ†æå‡è®¡ç®—å™¨")

    col1, col2, col3 = st.columns(3)
    with col1:
        weighted_current_score = st.number_input("å½“å‰åŠ æƒç»¼åˆè¯„åˆ†", 0.0, 5.0, 4.52, 0.01)
        score_1_year_ago = st.number_input("ä¸€å¹´å‰è¯„åˆ†", 0.0, 5.0, 4.60, 0.01)
    with col2:
        reviews_last_1_year = st.number_input("è¿‘ä¸€å¹´è¯„ä»·æ•°", 0, 10000, 300, 1)
        reviews_before_1_year = st.number_input("ä¸€å¹´å‰è¯„ä»·æ•°", 0, 10000, 500, 1)
    with col3:
        target_score = st.number_input("ç›®æ ‡è¯„åˆ†", 0.0, 5.0, 4.80, 0.01)

    def calculate_meituan():
        effective_old = reviews_before_1_year / 10.0
        total_weight = reviews_last_1_year + effective_old
        inferred_recent_score = (
            (weighted_current_score * total_weight - score_1_year_ago * effective_old)
            / reviews_last_1_year
        )
        if weighted_current_score >= target_score:
            return 0, inferred_recent_score

        numerator = (target_score * total_weight - score_1_year_ago * effective_old) - inferred_recent_score * reviews_last_1_year
        denominator = 5.0 - target_score
        if denominator <= 0:
            raise ValueError("ç›®æ ‡è¯„åˆ†è¿‡é«˜")
        required = math.ceil(numerator / denominator)
        return max(0, required), inferred_recent_score

    try:
        req, inferred = calculate_meituan()
        st.success(f"âœ… åæ¨å‡ºè¿‘ä¸€å¹´çœŸå®è¯„åˆ†ä¸ºï¼š**{inferred:.3f} åˆ†**")
        if req == 0:
            st.info(f"ğŸ‰ å½“å‰è¯„åˆ†å·²è¾¾æ ‡")
        else:
            st.warning(f"ğŸ“ˆ éœ€è¦è‡³å°‘ **{req}** æ¡ 5 æ˜Ÿå¥½è¯„")
    except Exception as e:
        st.error(f"âŒ è®¡ç®—é”™è¯¯ï¼š{str(e)}")

# ============ 3. è¯„è®ºç»´åº¦åˆ†æï¼ˆæ–°ï¼‰ ============
elif page == "ğŸ“ˆ è¯„è®ºç»´åº¦åˆ†æ":
    st.title("ğŸ“ˆ è¯„è®ºç»´åº¦åˆ†æï¼ˆåŸºäºæ–‡æœ¬æŒ–æ˜ï¼‰")

    st.markdown("ä¸Šä¼ åŒ…å« **è¯„è®ºå†…å®¹** åˆ—çš„ Excel æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æå–æ ‡ç­¾å¹¶åˆ†ææƒ…æ„Ÿã€‚")

    with st.expander("ğŸ“„ ç¤ºä¾‹æ ¼å¼"):
        st.write(pd.DataFrame({
            'è¯„è®ºå†…å®¹': ["ä½ç½®å¾ˆå¥½ï¼Œé è¿‘åœ°é“ï¼Œä½†æˆ¿é—´æœ‰ç‚¹å°ã€‚", "æ—©é¤ä¸°å¯Œï¼ŒæœåŠ¡çƒ­æƒ…ï¼Œå°±æ˜¯æœ‰ç‚¹åµã€‚"]
        }))

    uploaded_file = st.file_uploader("ä¸Šä¼ è¯„è®ºæ•°æ® (.xlsx)", type=["xlsx"])

    if uploaded_file:
        try:
            df = pd.read_excel(uploaded_file)
            st.success(f"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è¯„è®ºæ•°æ®")

            with st.expander("ğŸ“„ æ•°æ®é¢„è§ˆ"):
                st.dataframe(df.head())

            # æŸ¥æ‰¾è¯„è®ºåˆ—
            comment_col = None
            if 'è¯„è®ºå†…å®¹' in df.columns:
                comment_col = 'è¯„è®ºå†…å®¹'
            else:
                potential = [col for col in df.columns if 'è¯„è®º' in col or 'è¯„ä»·' in col or 'content' in col]
                if potential:
                    comment_col = potential[0]

            if not comment_col:
                st.error("âŒ æœªæ‰¾åˆ°è¯„è®ºåˆ—ï¼Œè¯·ç¡®ä¿åŒ…å«â€œè¯„è®ºâ€æˆ–â€œè¯„ä»·â€å…³é”®è¯çš„åˆ—ã€‚")
            else:
                # æå–æ ‡ç­¾è¯„åˆ†
                new_scores = extract_tags_with_scores(df[comment_col])

                if len(new_scores) == 0:
                    st.warning("âš ï¸ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ ‡ç­¾è¯„åˆ†")
                else:
                    all_scores = pd.Series(new_scores).sort_values(ascending=False)

                    # å¯è§†åŒ–
                    col1, col2 = st.columns(2)

                    with col1:
                        st.subheader("ğŸ“Š æŸ±çŠ¶å›¾ï¼šå„ç»´åº¦è¯„åˆ†")
                        filtered_scores = {k: v for k, v in all_scores.items() if 4.5 <= v <= 5.0}
                        fig1, ax1 = plt.subplots(figsize=(10, 6))
                        colors = ['green' if v >= 4.78 else 'red' for v in filtered_scores.values()]
                        pd.Series(filtered_scores).plot(kind='bar', ax=ax1, color=colors, alpha=0.8)
                        ax1.set_ylabel("è¯„åˆ†ï¼ˆæ»¡åˆ†5.0ï¼‰")
                        ax1.set_ylim(4.5, 5.0)
                        ax1.axhline(y=4.78, color='orange', linestyle='--', linewidth=1)
                        ax1.text(0.02, 4.8, 'ä¼˜ç§€çº¿ 4.78', transform=ax1.transData, fontsize=10, color='orange')
                        plt.xticks(rotation=45, ha='right')
                        plt.tight_layout()
                        st.pyplot(fig1)

                    with col2:
                        st.subheader("ğŸ“ˆ æ ‘çŠ¶å›¾ï¼ˆTreemapï¼‰")
                        fig2, ax2 = plt.subplots(figsize=(10, 6))
                        sizes = all_scores.values
                        colors = ['lightgreen' if v >= 4.78 else 'salmon' for v in all_scores]
                        labels = [f'{k}\n{v:.2f}' for k, v in all_scores.items()]
                        squarify.plot(sizes=sizes, label=labels, color=colors, alpha=0.8, ax=ax2, text_kwargs={'fontsize': 8})
                        ax2.set_title("è¯„åˆ†åˆ†å¸ƒ")
                        ax2.axis("off")
                        st.pyplot(fig2)

                    # ä¼˜åŒ–å»ºè®®
                    st.subheader("ğŸ’¡ ä¼˜åŒ–å»ºè®®ï¼ˆå¯ä¿®æ”¹ï¼‰")
                    needs_improvement = all_scores[all_scores < 4.78]
                    if len(needs_improvement) == 0:
                        st.success("ğŸ‰ æ‰€æœ‰ç»´åº¦å‡ â‰¥ 4.78ï¼Œè¡¨ç°ä¼˜ç§€ï¼")
                    else:
                        for dim, score in needs_improvement.items():
                            default_suggestion = SUGGESTIONS.get(dim, "è¯·è¡¥å……ä¼˜åŒ–å»ºè®®ã€‚")
                            st.markdown(f"### ğŸ“Œ {dim} ({score:.2f})")
                            st.text_area("å»ºè®®ï¼š", value=default_suggestion, height=100, key=f"sug_{dim}")

                    # å¯¼å‡ºåŸå§‹æ•°æ®
                    excel_data = to_excel(df)
                    b64 = base64.b64encode(excel_data).decode()
                    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="åŸå§‹è¯„è®ºæ•°æ®.xlsx">ğŸ“¥ ä¸‹è½½åŸå§‹æ•°æ®</a>'
                    st.markdown(href, unsafe_allow_html=True)

        except Exception as e:
            st.error(f"âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}")
            st.exception(e)

# ============ 4. æ™ºèƒ½è¯„è®ºå›å¤ ============
elif page == "ğŸ’¬ æ™ºèƒ½è¯„è®ºå›å¤":
    st.title("ğŸ’¬ æ™ºèƒ½è¯„è®ºå›å¤ç”Ÿæˆå™¨")

    col1, col2 = st.columns([3, 1])
    with col1:
        review_input = st.text_area("ç²˜è´´å®¢äººè¯„è®º", height=180, placeholder="è¯·åœ¨æ­¤è¾“å…¥æˆ–ç²˜è´´å®¢äººåœ¨æºç¨‹/ç¾å›¢ç­‰å¹³å°çš„è¯„è®º...")
    with col2:
        guest_name = st.text_input("å®¢äººå§“å", "å°Šæ•¬çš„å®¾å®¢")
        review_source = st.selectbox("å¹³å°æ¥æº", ["æºç¨‹", "ç¾å›¢", "é£çŒª", "å»å“ªå„¿", "æŠ–éŸ³"])

    if st.button("âœ¨ ç”Ÿæˆå›å¤", type="primary"):
        if not review_input.strip():
            st.warning("è¯·è¾“å…¥è¯„è®ºå†…å®¹ï¼")
        else:
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›å¤..."):
                prompt = generate_prompt(
                    review_input, guest_name,
                    st.session_state.hotel_name,
                    st.session_state.hotel_nickname,
                    review_source
                )
                raw_reply = call_qwen_api(prompt)
                reply = truncate_to_word_count(raw_reply) if not raw_reply.startswith("âŒ") else raw_reply
                word_count = len([c for c in reply if c.isalnum() or c in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘ã€Šã€‹ã€'])

            st.markdown(f"""
            <div style="background-color: #000000; color: #ffffff; padding: 12px; border-radius: 6px; font-size: 15px;">
            {reply}
            </div>
            <p style="color: #888; font-size: 14px; margin-top: 4px;">
            ğŸ”¤ å­—æ•°ï¼š{word_count} / 200ï¼ˆç›®æ ‡åŒºé—´ï¼š100â€“200ï¼‰
            </p>
            """, unsafe_allow_html=True)

            st.markdown("""
            <script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
            <button id="copy-btn" style="margin-top: 10px; padding: 8px 16px; background: #1f77b4; color: white; border: none; border-radius: 4px; cursor: pointer;">
                ğŸ“‹ å¤åˆ¶å›å¤
            </button>
            <script>
            const btn = document.getElementById('copy-btn');
            const text = document.querySelector('div[style*="background-color: #000000"]').innerText;
            const clipboard = new ClipboardJS('#copy-btn', { text: () => text });
            clipboard.on('success', function(e) {
                btn.innerText = 'âœ… å·²å¤åˆ¶ï¼';
                setTimeout(() => { btn.innerText = 'ğŸ“‹ å¤åˆ¶å›å¤'; }, 2000);
            });
            </script>
            """, unsafe_allow_html=True)

            if st.button("ğŸ’¾ ä¿å­˜åˆ°å†å²"):
                st.session_state.history.append({
                    "time": time.strftime("%H:%M"),
                    "hotel": st.session_state.hotel_name,
                    "name": guest_name,
                    "review": review_input[:50] + "...",
                    "reply": reply,
                    "word_count": word_count
                })
                st.success("å·²ä¿å­˜è‡³å†å²è®°å½•")

    if st.session_state.history:
        st.subheader("ğŸ•’ å†å²è®°å½•")
        for idx, h in enumerate(reversed(st.session_state.history)):
            with st.expander(f"ã€{h['time']}ã€‘{h['hotel']} | {h['name']} | {h['word_count']}å­—"):
                st.markdown(f"""
                <div style="background-color: #000000; color: #ffffff; padding: 12px; border-radius: 6px; font-size: 15px;">
                {h['reply']}
                </div>
                """, unsafe_allow_html=True)
                if st.button(f"ğŸ—‘ï¸ åˆ é™¤è®°å½• {idx}", key=f"del_{idx}"):
                    st.session_state.history.pop(-idx-1)
                    st.experimental_rerun()

# ============ API Key æé†’ ============
if page == "ğŸ’¬ æ™ºèƒ½è¯„è®ºå›å¤" and not os.getenv("QWEN_API_KEY"):
    st.warning("âš ï¸ è¯·åœ¨ Streamlit Cloud çš„ Secrets ä¸­è®¾ç½® `QWEN_API_KEY`")
